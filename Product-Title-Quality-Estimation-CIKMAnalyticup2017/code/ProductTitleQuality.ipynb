{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49301f96-2d89-4f64-b00d-bbad249d351a",
   "metadata": {},
   "source": [
    "# Information Retrieval Project\n",
    "\n",
    "Bagging Model for Product Title Quality with Noise\n",
    "\n",
    "CIKM AnalytiCup 2017\n",
    "\n",
    "Aarib Ahmed Vahidy\n",
    "\n",
    "Partham Kumar Chawla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76193a2e-03df-4662-bf23-6d7c74546e1c",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a550baa-a3b5-43a5-9caf-86ad3c7dafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aarib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\aarib\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn xgboost lightgbm nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b0bcde-d2ca-4af5-ab25-97bd2a2e59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a001efb-dd61-4266-a570-f371f8950c97",
   "metadata": {},
   "source": [
    "### Data Loading and Label Integration\n",
    "\n",
    "Training and validation datasets are loaded from CSV files.\n",
    "\n",
    "Corresponding labels (clarity and conciseness) are loaded from separate .labels and .predict files.\n",
    "\n",
    "These labels are assigned meaningful column names.\n",
    "\n",
    "The label files are then concatenated with their respective main datasets.\n",
    "\n",
    "Column names of both train and validation DataFrames are standardized for consistency and easier downstream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff37f8-433a-403d-b424-5ab074be6e48",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1688146f-3b4a-44d4-926d-178d4803a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (36283, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my</th>\n",
       "      <th>AD674FAASTLXANMY</th>\n",
       "      <th>Adana Gallery Suri Square Hijab – Light Pink</th>\n",
       "      <th>Fashion</th>\n",
       "      <th>Women</th>\n",
       "      <th>Muslim Wear</th>\n",
       "      <th>&lt;ul&gt;&lt;li&gt;Material : Non sheer shimmer chiffon&lt;/li&gt;&lt;li&gt;Sizes : 52 x 52 inches OR 56 x 56 inches&lt;/li&gt;&lt;li&gt;Cut with curved ends&lt;/li&gt;&lt;/ul&gt;</th>\n",
       "      <th>49.0</th>\n",
       "      <th>local</th>\n",
       "      <th>clarity</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>AE068HBAA3RPRDANMY</td>\n",
       "      <td>Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Bath &amp; Body</td>\n",
       "      <td>Hand &amp; Foot Care</td>\n",
       "      <td>Formulated with oil-free hydrating botanicals/...</td>\n",
       "      <td>128.00</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>AN680ELAA9VN57ANMY</td>\n",
       "      <td>Andoer 150cm Cellphone Smartphone Mini Dual-He...</td>\n",
       "      <td>TV, Audio / Video, Gaming &amp; Wearables</td>\n",
       "      <td>Audio</td>\n",
       "      <td>Live Sound &amp; Stage</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;150cm mini microphone compatible for ...</td>\n",
       "      <td>25.07</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>AN957HBAAAHDF4ANMY</td>\n",
       "      <td>ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Shampoos &amp; Conditioners</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;ANMYNA Complaint Silky Set (Shampoo 5...</td>\n",
       "      <td>118.00</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>AR511HBAXNWAANMY</td>\n",
       "      <td>Argital Argiltubo Green Clay For Face and Body...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Men's Care</td>\n",
       "      <td>Body and Skin Care</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;100% Authentic&lt;/li&gt; &lt;li&gt;Rrefresh and ...</td>\n",
       "      <td>114.80</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>AS575ELCMZ4WANMY</td>\n",
       "      <td>Asus TP300LJ-DW004H Transformer Book Flip 4GB ...</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Traditional Laptops</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>2599.00</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   my    AD674FAASTLXANMY       Adana Gallery Suri Square Hijab – Light Pink  \\\n",
       "0  my  AE068HBAA3RPRDANMY  Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz   \n",
       "1  my  AN680ELAA9VN57ANMY  Andoer 150cm Cellphone Smartphone Mini Dual-He...   \n",
       "2  my  AN957HBAAAHDF4ANMY  ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...   \n",
       "3  my    AR511HBAXNWAANMY  Argital Argiltubo Green Clay For Face and Body...   \n",
       "4  my    AS575ELCMZ4WANMY  Asus TP300LJ-DW004H Transformer Book Flip 4GB ...   \n",
       "\n",
       "                                 Fashion        Women  \\\n",
       "0                        Health & Beauty  Bath & Body   \n",
       "1  TV, Audio / Video, Gaming & Wearables        Audio   \n",
       "2                        Health & Beauty    Hair Care   \n",
       "3                        Health & Beauty   Men's Care   \n",
       "4                    Computers & Laptops      Laptops   \n",
       "\n",
       "               Muslim Wear  \\\n",
       "0         Hand & Foot Care   \n",
       "1       Live Sound & Stage   \n",
       "2  Shampoos & Conditioners   \n",
       "3       Body and Skin Care   \n",
       "4      Traditional Laptops   \n",
       "\n",
       "  <ul><li>Material : Non sheer shimmer chiffon</li><li>Sizes : 52 x 52 inches OR 56 x 56 inches</li><li>Cut with curved ends</li></ul>  \\\n",
       "0  Formulated with oil-free hydrating botanicals/...                                                                                     \n",
       "1  <ul> <li>150cm mini microphone compatible for ...                                                                                     \n",
       "2  <ul> <li>ANMYNA Complaint Silky Set (Shampoo 5...                                                                                     \n",
       "3  <ul> <li>100% Authentic</li> <li>Rrefresh and ...                                                                                     \n",
       "4  <div class=\"prod_content\"> <div class=\"prod_de...                                                                                     \n",
       "\n",
       "      49.0          local  clarity  conciseness  \n",
       "0   128.00  international        1            1  \n",
       "1    25.07  international        1            1  \n",
       "2   118.00          local        1            0  \n",
       "3   114.80  international        1            1  \n",
       "4  2599.00          local        1            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the main data\n",
    "data_train = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\training\\data_train.csv')\n",
    "\n",
    "#Loading labels\n",
    "clarity_labels = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\training\\clarity_train.labels', header=None)\n",
    "conciseness_labels = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\training\\conciseness_train.labels', header=None)\n",
    "\n",
    "#Assigning meaningful column names\n",
    "clarity_labels.columns = ['clarity']\n",
    "conciseness_labels.columns = ['conciseness']\n",
    "\n",
    "#Combining everything into one DataFrame\n",
    "train = pd.concat([data_train, clarity_labels, conciseness_labels], axis=1)\n",
    "\n",
    "print(\"Shape of training data:\", train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f764e-2cad-4da7-a284-2c88cf287f4f",
   "metadata": {},
   "source": [
    "### Adding column names to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99798e32-1872-4ead-bf8d-2dc4890156a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = [\n",
    "    'country', 'product_id', 'title', \n",
    "    'category_lvl_1', 'category_lvl_2', 'category_lvl_3',\n",
    "    'description', 'price', 'delivery_type', \n",
    "    'clarity', 'conciseness'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd508c4-7245-4814-b62f-9bac21aa8a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>product_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category_lvl_1</th>\n",
       "      <th>category_lvl_2</th>\n",
       "      <th>category_lvl_3</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>delivery_type</th>\n",
       "      <th>clarity</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>AE068HBAA3RPRDANMY</td>\n",
       "      <td>Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Bath &amp; Body</td>\n",
       "      <td>Hand &amp; Foot Care</td>\n",
       "      <td>Formulated with oil-free hydrating botanicals/...</td>\n",
       "      <td>128.00</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>AN680ELAA9VN57ANMY</td>\n",
       "      <td>Andoer 150cm Cellphone Smartphone Mini Dual-He...</td>\n",
       "      <td>TV, Audio / Video, Gaming &amp; Wearables</td>\n",
       "      <td>Audio</td>\n",
       "      <td>Live Sound &amp; Stage</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;150cm mini microphone compatible for ...</td>\n",
       "      <td>25.07</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>AN957HBAAAHDF4ANMY</td>\n",
       "      <td>ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Shampoos &amp; Conditioners</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;ANMYNA Complaint Silky Set (Shampoo 5...</td>\n",
       "      <td>118.00</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>AR511HBAXNWAANMY</td>\n",
       "      <td>Argital Argiltubo Green Clay For Face and Body...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Men's Care</td>\n",
       "      <td>Body and Skin Care</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;100% Authentic&lt;/li&gt; &lt;li&gt;Rrefresh and ...</td>\n",
       "      <td>114.80</td>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>AS575ELCMZ4WANMY</td>\n",
       "      <td>Asus TP300LJ-DW004H Transformer Book Flip 4GB ...</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Traditional Laptops</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>2599.00</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country          product_id  \\\n",
       "0      my  AE068HBAA3RPRDANMY   \n",
       "1      my  AN680ELAA9VN57ANMY   \n",
       "2      my  AN957HBAAAHDF4ANMY   \n",
       "3      my    AR511HBAXNWAANMY   \n",
       "4      my    AS575ELCMZ4WANMY   \n",
       "\n",
       "                                               title  \\\n",
       "0  Cuba Heartbreaker Eau De Parfum Spray 100ml/3.3oz   \n",
       "1  Andoer 150cm Cellphone Smartphone Mini Dual-He...   \n",
       "2  ANMYNA Complaint Silky Set 柔顺洗发配套 (Shampoo 520...   \n",
       "3  Argital Argiltubo Green Clay For Face and Body...   \n",
       "4  Asus TP300LJ-DW004H Transformer Book Flip 4GB ...   \n",
       "\n",
       "                          category_lvl_1 category_lvl_2  \\\n",
       "0                        Health & Beauty    Bath & Body   \n",
       "1  TV, Audio / Video, Gaming & Wearables          Audio   \n",
       "2                        Health & Beauty      Hair Care   \n",
       "3                        Health & Beauty     Men's Care   \n",
       "4                    Computers & Laptops        Laptops   \n",
       "\n",
       "            category_lvl_3                                        description  \\\n",
       "0         Hand & Foot Care  Formulated with oil-free hydrating botanicals/...   \n",
       "1       Live Sound & Stage  <ul> <li>150cm mini microphone compatible for ...   \n",
       "2  Shampoos & Conditioners  <ul> <li>ANMYNA Complaint Silky Set (Shampoo 5...   \n",
       "3       Body and Skin Care  <ul> <li>100% Authentic</li> <li>Rrefresh and ...   \n",
       "4      Traditional Laptops  <div class=\"prod_content\"> <div class=\"prod_de...   \n",
       "\n",
       "     price  delivery_type  clarity  conciseness  \n",
       "0   128.00  international        1            1  \n",
       "1    25.07  international        1            1  \n",
       "2   118.00          local        1            0  \n",
       "3   114.80  international        1            1  \n",
       "4  2599.00          local        1            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7812ee7-802e-4b4c-9cc6-686be4c71c81",
   "metadata": {},
   "source": [
    "### Loading validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92598a27-25cf-4787-b5d8-8b057c42ee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation data: (11838, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my</th>\n",
       "      <th>AP564ELASSTWANMY</th>\n",
       "      <th>Apple MacBook Pro MGXC2ZP/A 16GB i7 15.4-inch Retina Display Laptop</th>\n",
       "      <th>Computers &amp; Laptops</th>\n",
       "      <th>Laptops</th>\n",
       "      <th>Macbooks</th>\n",
       "      <th>OS X Lion&lt;br&gt; Intel Core i7&lt;br&gt; 15-inch Retina Display&lt;br&gt; 16GB RAM / 512GB Flash&lt;br&gt; GeForce GT 750M&lt;br&gt; WiFi + BT4 + RJ45&lt;br&gt;</th>\n",
       "      <th>12550.0</th>\n",
       "      <th>local</th>\n",
       "      <th>clarity</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>BR924HBAA5B3TLANMY</td>\n",
       "      <td>BRAND'S® American Ginseng Triple Pack (3x 6's)...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Food Supplements</td>\n",
       "      <td>Well Being</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;Traditionally used to calm the mind a...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>0.98747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>CA673ELAA5UG3XANMY</td>\n",
       "      <td>Canon EOS M10 Mirrorless Digital Camera 18MP w...</td>\n",
       "      <td>Cameras</td>\n",
       "      <td>Mirrorless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;div&gt; &lt;ul&gt; &lt;li&gt;18.0MP APS-C CMOS Sensor&lt;/li&gt; &lt;...</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.22758</td>\n",
       "      <td>0.29770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>DE759ELAA7QM1XANMY</td>\n",
       "      <td>Dell LED Monitor 23\" (E2316H)</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Computer Accessories</td>\n",
       "      <td>Monitors</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>565.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.36162</td>\n",
       "      <td>0.59796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>ES802OTAABHAY8ANMY</td>\n",
       "      <td>Esprit Tallac Brave Nubuck Sand ES107601001 Be...</td>\n",
       "      <td>Watches Sunglasses Jewellery</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Men</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;stainless steel case&lt;/li&gt; &lt;li&gt;mineral...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.83418</td>\n",
       "      <td>0.56371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>HP961ELAABF7N7ANMY</td>\n",
       "      <td>(Refurbished) HP Compaq 3330 Pro MT + 19\" LCD</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Desktops Computers</td>\n",
       "      <td>All-purpose</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;Model : HP Compaq 3330 Pro MT + 19\" L...</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.12018</td>\n",
       "      <td>0.50220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   my    AP564ELASSTWANMY  \\\n",
       "0  my  BR924HBAA5B3TLANMY   \n",
       "1  my  CA673ELAA5UG3XANMY   \n",
       "2  my  DE759ELAA7QM1XANMY   \n",
       "3  my  ES802OTAABHAY8ANMY   \n",
       "4  my  HP961ELAABF7N7ANMY   \n",
       "\n",
       "  Apple MacBook Pro MGXC2ZP/A 16GB i7 15.4-inch Retina Display Laptop  \\\n",
       "0  BRAND'S® American Ginseng Triple Pack (3x 6's)...                    \n",
       "1  Canon EOS M10 Mirrorless Digital Camera 18MP w...                    \n",
       "2                      Dell LED Monitor 23\" (E2316H)                    \n",
       "3  Esprit Tallac Brave Nubuck Sand ES107601001 Be...                    \n",
       "4      (Refurbished) HP Compaq 3330 Pro MT + 19\" LCD                    \n",
       "\n",
       "            Computers & Laptops               Laptops     Macbooks  \\\n",
       "0               Health & Beauty      Food Supplements   Well Being   \n",
       "1                       Cameras            Mirrorless          NaN   \n",
       "2           Computers & Laptops  Computer Accessories     Monitors   \n",
       "3  Watches Sunglasses Jewellery               Watches          Men   \n",
       "4           Computers & Laptops    Desktops Computers  All-purpose   \n",
       "\n",
       "  OS X Lion<br> Intel Core i7<br> 15-inch Retina Display<br> 16GB RAM / 512GB Flash<br> GeForce GT 750M<br> WiFi + BT4 + RJ45<br>  \\\n",
       "0  <ul> <li>Traditionally used to calm the mind a...                                                                                \n",
       "1  <div> <ul> <li>18.0MP APS-C CMOS Sensor</li> <...                                                                                \n",
       "2  <div class=\"prod_content\"> <div class=\"prod_de...                                                                                \n",
       "3  <ul> <li>stainless steel case</li> <li>mineral...                                                                                \n",
       "4  <ul> <li>Model : HP Compaq 3330 Pro MT + 19\" L...                                                                                \n",
       "\n",
       "   12550.0  local  clarity  conciseness  \n",
       "0    105.0  local  0.34139      0.98747  \n",
       "1   1588.0  local  0.22758      0.29770  \n",
       "2    565.0  local  0.36162      0.59796  \n",
       "3    279.0  local  0.83418      0.56371  \n",
       "4   1259.0  local  0.12018      0.50220  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the main data\n",
    "data_val = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\validation\\data_valid.csv')\n",
    "\n",
    "#Loading labels\n",
    "clarity_labels = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\validation\\clarity_valid.predict', header=None)\n",
    "conciseness_labels = pd.read_csv(r'C:\\Users\\aarib\\6thSemester\\IR\\IRProject\\Product Title Classification\\CIKMAnalytiCup2017_Lazada\\validation\\conciseness_valid.predict', header=None)\n",
    "\n",
    "#Assigning meaningful column names\n",
    "clarity_labels.columns = ['clarity']\n",
    "conciseness_labels.columns = ['conciseness']\n",
    "\n",
    "#Combining everything into one DataFrame\n",
    "validation = pd.concat([data_val, clarity_labels, conciseness_labels], axis=1)\n",
    "\n",
    "print(\"Shape of validation data:\", validation.shape)\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039590bc-21d2-48b9-8b91-d6021a02b216",
   "metadata": {},
   "source": [
    "### Adding column names to validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7a9904-3219-4031-9aed-1401c808bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.columns = [\n",
    "    'country', 'product_id', 'title', \n",
    "    'category_lvl_1', 'category_lvl_2', 'category_lvl_3',\n",
    "    'description', 'price', 'delivery_type', \n",
    "    'clarity', 'conciseness'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2930870f-c503-4fc1-8a1f-bb037e27cd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>product_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category_lvl_1</th>\n",
       "      <th>category_lvl_2</th>\n",
       "      <th>category_lvl_3</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>delivery_type</th>\n",
       "      <th>clarity</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>BR924HBAA5B3TLANMY</td>\n",
       "      <td>BRAND'S® American Ginseng Triple Pack (3x 6's)...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Food Supplements</td>\n",
       "      <td>Well Being</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;Traditionally used to calm the mind a...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>0.98747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my</td>\n",
       "      <td>CA673ELAA5UG3XANMY</td>\n",
       "      <td>Canon EOS M10 Mirrorless Digital Camera 18MP w...</td>\n",
       "      <td>Cameras</td>\n",
       "      <td>Mirrorless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;div&gt; &lt;ul&gt; &lt;li&gt;18.0MP APS-C CMOS Sensor&lt;/li&gt; &lt;...</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.22758</td>\n",
       "      <td>0.29770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>DE759ELAA7QM1XANMY</td>\n",
       "      <td>Dell LED Monitor 23\" (E2316H)</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Computer Accessories</td>\n",
       "      <td>Monitors</td>\n",
       "      <td>&lt;div class=\"prod_content\"&gt; &lt;div class=\"prod_de...</td>\n",
       "      <td>565.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.36162</td>\n",
       "      <td>0.59796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>ES802OTAABHAY8ANMY</td>\n",
       "      <td>Esprit Tallac Brave Nubuck Sand ES107601001 Be...</td>\n",
       "      <td>Watches Sunglasses Jewellery</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Men</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;stainless steel case&lt;/li&gt; &lt;li&gt;mineral...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.83418</td>\n",
       "      <td>0.56371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>HP961ELAABF7N7ANMY</td>\n",
       "      <td>(Refurbished) HP Compaq 3330 Pro MT + 19\" LCD</td>\n",
       "      <td>Computers &amp; Laptops</td>\n",
       "      <td>Desktops Computers</td>\n",
       "      <td>All-purpose</td>\n",
       "      <td>&lt;ul&gt; &lt;li&gt;Model : HP Compaq 3330 Pro MT + 19\" L...</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>local</td>\n",
       "      <td>0.12018</td>\n",
       "      <td>0.50220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country          product_id  \\\n",
       "0      my  BR924HBAA5B3TLANMY   \n",
       "1      my  CA673ELAA5UG3XANMY   \n",
       "2      my  DE759ELAA7QM1XANMY   \n",
       "3      my  ES802OTAABHAY8ANMY   \n",
       "4      my  HP961ELAABF7N7ANMY   \n",
       "\n",
       "                                               title  \\\n",
       "0  BRAND'S® American Ginseng Triple Pack (3x 6's)...   \n",
       "1  Canon EOS M10 Mirrorless Digital Camera 18MP w...   \n",
       "2                      Dell LED Monitor 23\" (E2316H)   \n",
       "3  Esprit Tallac Brave Nubuck Sand ES107601001 Be...   \n",
       "4      (Refurbished) HP Compaq 3330 Pro MT + 19\" LCD   \n",
       "\n",
       "                 category_lvl_1        category_lvl_2 category_lvl_3  \\\n",
       "0               Health & Beauty      Food Supplements     Well Being   \n",
       "1                       Cameras            Mirrorless            NaN   \n",
       "2           Computers & Laptops  Computer Accessories       Monitors   \n",
       "3  Watches Sunglasses Jewellery               Watches            Men   \n",
       "4           Computers & Laptops    Desktops Computers    All-purpose   \n",
       "\n",
       "                                         description   price delivery_type  \\\n",
       "0  <ul> <li>Traditionally used to calm the mind a...   105.0         local   \n",
       "1  <div> <ul> <li>18.0MP APS-C CMOS Sensor</li> <...  1588.0         local   \n",
       "2  <div class=\"prod_content\"> <div class=\"prod_de...   565.0         local   \n",
       "3  <ul> <li>stainless steel case</li> <li>mineral...   279.0         local   \n",
       "4  <ul> <li>Model : HP Compaq 3330 Pro MT + 19\" L...  1259.0         local   \n",
       "\n",
       "   clarity  conciseness  \n",
       "0  0.34139      0.98747  \n",
       "1  0.22758      0.29770  \n",
       "2  0.36162      0.59796  \n",
       "3  0.83418      0.56371  \n",
       "4  0.12018      0.50220  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d00db-bcad-4188-867b-ba5ba3229145",
   "metadata": {},
   "source": [
    "### Text Cleaning & Vectorization\n",
    "\n",
    "A custom function clean_text():\n",
    "\n",
    "Removes HTML tags using BeautifulSoup\n",
    "\n",
    "Eliminates special characters and digits\n",
    "\n",
    "Converts text to lowercase\n",
    "\n",
    "Strips extra whitespace\n",
    "\n",
    "This function is applied to both the product title and description for the training and validation sets.\n",
    "\n",
    "The cleaned title and description are concatenated to form a new feature called text.\n",
    "\n",
    "Then:\n",
    "\n",
    "A character-level n-gram vectorizer is defined using CountVectorizer with ngram_range=(2, 6) and max_features=5000, as outlined in the original paper.\n",
    "\n",
    "The vectorizer is fitted on the training text, and both training and validation texts are transformed into numerical feature vectors.\n",
    "\n",
    "Finally, the target variables y_clarity and y_conciseness are extracted for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915b7948-ef82-4aa0-83fd-303f29dcf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    #Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    #Remove special characters and digits\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    #Convert to lowercase\n",
    "    text = text.lower()\n",
    "    #Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "#Applying transformations  to both train and validation sets\n",
    "for df in [train, validation]:\n",
    "    df['clean_title'] = df['title'].apply(clean_text)\n",
    "    df['clean_desc'] = df['description'].apply(clean_text)\n",
    "    df['text'] = df['clean_title'] + \" \" + df['clean_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6912c85b-a669-49f7-9e3e-f7834c1a31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using character n-grams as described in the paper (ngram_range = (2,6))\n",
    "char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 6), max_features=5000)\n",
    "\n",
    "#Fitting on train text, transform train and validation\n",
    "X_train = char_vectorizer.fit_transform(train['text'])\n",
    "X_val = char_vectorizer.transform(validation['text'])\n",
    "\n",
    "#Targets\n",
    "y_clarity = train['clarity']\n",
    "y_conciseness = train['conciseness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a40e2b-403d-4303-aff7-9f4ee1e509e6",
   "metadata": {},
   "source": [
    "### Bagged Ensemble Model Training with LightGBM\n",
    "\n",
    "This section implements a robust ensemble strategy to improve prediction accuracy by reducing variance:\n",
    "\n",
    "Model Choice:\n",
    "\n",
    "Used LightGBM Regressor (LGBMRegressor) for its speed and performance on high-dimensional, sparse data (like character n-grams).\n",
    "\n",
    "Ensemble Strategy – Bagging + K-Fold CV:\n",
    "\n",
    "Bagging (n_bags=4): Run the full 10-fold cross-validation process four times with different random seeds to simulate different “bags” of models.\n",
    "\n",
    "K-Fold Cross-Validation (n_folds=10): Each bag uses 10-fold CV to split the training data into training and validation subsets.\n",
    "\n",
    "In total, 40 models are trained (4 bags × 10 folds).\n",
    "\n",
    "Predictions from all models are averaged to produce final validation predictions.\n",
    "\n",
    "Model Configuration:\n",
    "\n",
    "n_estimators=300: Each model trains up to 300 boosting iterations.\n",
    "\n",
    "learning_rate=0.05: Slower learning for better generalization.\n",
    "\n",
    "num_leaves=31: Controls model complexity.\n",
    "\n",
    "random_state: Varied per bag to encourage diversity in learned models.\n",
    "\n",
    "Data Compatibility Fix:\n",
    "\n",
    "Transformed X_train and X_val to np.float32 to resolve type compatibility errors with LightGBM (which expects float32 or float64 input, not int64).\n",
    "\n",
    "Target-wise Training:\n",
    "\n",
    "The process is run independently for both target variables:\n",
    "\n",
    "clarity\n",
    "\n",
    "conciseness\n",
    "\n",
    "This setup helps create more stable and generalizable predictions by aggregating results from a diverse set of models trained on different subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2bdd61a-8732-4b0c-8c73-d8e9b32bd042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble for CLARITY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.407419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36642\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 1it [00:29, 29.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.463508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36547\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 2it [01:00, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.364475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36533\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 3it [01:29, 29.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.314961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36484\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 4it [01:58, 29.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.304809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36555\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 5it [02:27, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.325908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36579\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 6it [02:56, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.239547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36568\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 7it [03:25, 29.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.254350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36588\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 8it [03:54, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.462657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36336\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 9it [04:24, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.283993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36654\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 10it [04:53, 29.36s/it]\n",
      "Bag 2/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.292463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36480\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 1it [00:29, 29.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.328388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36593\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 2it [00:58, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.531994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36604\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 3it [01:28, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.439848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36595\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 4it [01:58, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.276306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36642\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 5it [02:27, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.349372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36328\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.944021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 6it [02:56, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.330854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36369\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 7it [03:25, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.251002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36655\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 8it [03:53, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.308800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36602\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 9it [04:22, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.278358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36564\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 10it [04:50, 29.08s/it]\n",
      "Bag 3/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.324436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36540\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 1it [00:29, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.365287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36543\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 2it [00:57, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.424073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36609\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 3it [01:27, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.508627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36589\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 4it [01:57, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.349576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36596\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 5it [02:26, 29.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.498272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36607\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 6it [02:56, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.440403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36507\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.944082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 7it [03:26, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.432217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36442\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 8it [03:56, 29.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.279957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36489\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 9it [04:25, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.319927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36563\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 10it [04:54, 29.41s/it]\n",
      "Bag 4/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.339730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36583\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 1it [00:29, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.531009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36601\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 2it [00:59, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.465576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36569\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 3it [01:29, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.382676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36542\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 4it [01:58, 29.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.447751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36329\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.942704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 5it [02:27, 29.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.439655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36535\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 6it [02:58, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.248675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36483\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 7it [03:26, 29.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.504953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36547\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 8it [03:57, 29.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.213508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36611\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 9it [04:25, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.242355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36587\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.943653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 10it [04:54, 29.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ensemble for CONCISENESS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.345949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36642\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 1it [00:29, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.213448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36547\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 2it [00:56, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.408899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36533\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 3it [01:26, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.317140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36484\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 4it [01:55, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.289175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36555\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 5it [02:24, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.484897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36579\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 6it [02:54, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.311157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36568\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 7it [03:23, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.349879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36588\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 8it [03:53, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.343261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36336\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 9it [04:22, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.310768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36654\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 1/4: 10it [04:52, 29.22s/it]\n",
      "Bag 2/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.394535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36480\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 1it [00:28, 28.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.496306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36593\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 2it [00:38, 17.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.493557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36604\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 3it [00:50, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.533357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36595\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 4it [01:03, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.594559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36642\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 5it [01:15, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.495168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36328\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 6it [01:26, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.655068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36369\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 7it [01:39, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.534390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36655\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 8it [01:51, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.436141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36602\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 9it [02:02, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.534146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36564\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.682774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 2/4: 10it [02:14, 13.48s/it]\n",
      "Bag 3/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.599762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36540\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.683990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 1it [00:11, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.534254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36543\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 2it [00:23, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.593168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36609\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 3it [00:35, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.544267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36589\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 4it [00:47, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.546027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36596\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 5it [00:59, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.514510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36607\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 6it [01:11, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.487307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36507\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 7it [01:23, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.450996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36442\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 8it [01:34, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.553108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36489\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 9it [01:46, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.535348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36563\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 3/4: 10it [01:58, 11.87s/it]\n",
      "Bag 4/4: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.611548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36583\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 1it [00:11, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.514088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36601\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 2it [00:24, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.557074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36569\n",
      "[LightGBM] [Info] Number of data points in the train set: 32654, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 3it [00:36, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.480498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36542\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 4it [00:48, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.566565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36329\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.684244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 5it [01:00, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.535702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36535\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 6it [01:12, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.526817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36483\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 7it [01:25, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.699698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36547\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 8it [01:39, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.491581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36611\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.686357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 9it [01:51, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.586812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36587\n",
      "[LightGBM] [Info] Number of data points in the train set: 32655, number of used features: 5000\n",
      "[LightGBM] [Info] Start training from score 0.685439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bag 4/4: 10it [02:03, 12.31s/it]\n"
     ]
    }
   ],
   "source": [
    "def run_lgbm_bagged(X, y, X_val, n_bags=4, n_folds=10):\n",
    "    val_preds = np.zeros(X_val.shape[0])\n",
    "    \n",
    "    for bag in range(n_bags):\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42 + bag)\n",
    "        for train_idx, valid_idx in tqdm(kf.split(X), desc=f\"Bag {bag+1}/{n_bags}\"):\n",
    "            X_train_kf, X_valid_kf = X[train_idx], X[valid_idx]\n",
    "            y_train_kf, y_valid_kf = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "            \n",
    "            model = lgb.LGBMRegressor(\n",
    "                n_estimators=300,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=-1,\n",
    "                num_leaves=31,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "            val_preds += model.predict(X_val) / (n_folds * n_bags)\n",
    "    \n",
    "    return val_preds\n",
    "\n",
    "\n",
    "# Fix dtype for LightGBM\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "\n",
    "# Run for both targets\n",
    "print(\"Training ensemble for CLARITY...\")\n",
    "val_preds_clarity = run_lgbm_bagged(X_train, y_clarity, X_val)\n",
    "\n",
    "print(\"\\nTraining ensemble for CONCISENESS...\")\n",
    "val_preds_conciseness = run_lgbm_bagged(X_train, y_conciseness, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775af1d2-f2b5-4682-b567-c56a87618b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE - Clarity: 0.52931\n",
      "Validation RMSE - Conciseness: 0.35273\n"
     ]
    }
   ],
   "source": [
    "#Extracting actual labels from validation set\n",
    "y_val = validation[['clarity', 'conciseness']]\n",
    "\n",
    "#Calculate RMSE\n",
    "rmse_clarity = mean_squared_error(y_val['clarity'], val_preds_clarity, squared=False)\n",
    "rmse_conciseness = mean_squared_error(y_val['conciseness'], val_preds_conciseness, squared=False)\n",
    "\n",
    "print(f\"Validation RMSE - Clarity: {rmse_clarity:.5f}\")\n",
    "print(f\"Validation RMSE - Conciseness: {rmse_conciseness:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764d2d2-b6fa-4334-a9e8-b3cbe4c4b141",
   "metadata": {},
   "source": [
    "### Results Comparison: Our Implementation vs. Research Paper\n",
    "\n",
    "This section compares our model’s validation performance with the results reported in the CIKM AnalytiCup 2017 paper titled \"Lazada Product Title\n",
    "Quality Challenge Bagging Model for Product Title Quality with Noise\".\n",
    "\n",
    "Target\t     Algorithm\t   Paper RMSE\t  Our RMSE\n",
    "Conciseness\t XGBoost\t      0.31553\t   0.35273\n",
    "Clarity\t     XGBoost\t      0.20745\t   0.52931\n",
    "\n",
    "Observations:\n",
    "Our RMSE values are higher, particularly for the Clarity task.\n",
    "\n",
    "The paper’s results were achieved using additional techniques such as:\n",
    "\n",
    "Ensemble of different algorithms (e.g., XGBoost, Ridge, SVR)\n",
    "\n",
    "More aggressive hyperparameter tuning\n",
    "\n",
    "Possibly more preprocessing steps or feature engineering\n",
    "\n",
    "Our pipeline is simpler (using only LightGBM + character n-grams), but still reasonably competitive for conciseness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
