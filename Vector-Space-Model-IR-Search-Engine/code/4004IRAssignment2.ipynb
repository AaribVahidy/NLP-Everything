{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7215283-a9b9-48ac-92a3-0d806389182a",
   "metadata": {},
   "source": [
    "# Aarib Ahmed Vahidy 22K-4004 BAI-6A\n",
    "\n",
    "## Information Retrieval Assignment # 2\n",
    "\n",
    "### Vector Space Model(VSM) for information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaaed7-08bf-4063-b1d6-a62a16c1a8e6",
   "metadata": {},
   "source": [
    "Assignment Objective\n",
    "\n",
    "This assignment focuses on Vector Space Model(VSM) for information retrieval. You will be\n",
    "implementing and testing a set of queries using VSM for information retrieval. You need to build\n",
    "a vector space of features using some specified feature selection techniques. The dimension of the\n",
    "space will be Rn, the query is also represented in the same feature space. Cosine similarity is used\n",
    "to compute the similarity between documents and queries. A given threshold can be used to filter\n",
    "the results for a given query. The threshold should be fixed for a given set for queries.\n",
    "\n",
    "Datasets\n",
    "\n",
    "You are given a collection of Abstracts (File name: Abstracts.zip) for implementing inverted index\n",
    "and positional index. This zip file contains 448 abstracts of some computer science journal. The\n",
    "language of all these documents are English. You also need to implement a pre-processing\n",
    "pipeline. It is recommended to first review the given text file for indexing. You need to treat each\n",
    "document as a unique document. This observation offers you many clues for your pipeline\n",
    "implementation and feature extraction. You will be implementing term feature selection based on\n",
    "Term Frequency (tf) and Inverse Document Frequency (idf) scoring. The parameters of tf and idf\n",
    "can be set while creating a specific space of representation. The set of queries are also provided\n",
    "for this assignment. You need to place the queries on the same space and compute the score based\n",
    "on cosine similarity. The weighting scheme used for VSM will be tf*idf, which is a combination\n",
    "of both tf (term frequency of term t in a document) and idf (inverse document frequency computing\n",
    "as (log(df)/ N).\n",
    "\n",
    "Query Processing\n",
    "\n",
    "The query processing of VSM is quite tricky, you need of optimize every aspect of computation.\n",
    "The high-dimensional vector product and similarity values of query (q) and documents (d) need to\n",
    "optimized.\n",
    "\n",
    "Basic Assumption for Vector Space Model (VSM) Retrieval Model\n",
    "\n",
    "1.Simple model based on linear algebra. Terms are considered as features using a weighting\n",
    "scheme.\n",
    "\n",
    "2.Allows partial matching of documents with the queries. Hence, able to produce good institutive \n",
    "scoring. Continuous scoring between queries and documents.\n",
    "\n",
    "3.Ranking of documents are possible using relevance score between document and query.\n",
    "As we discussed during the lectures, we will implement a VSM Model by selecting features from\n",
    "the document by specifying tf and idf values. You are free to implement a posting list with your\n",
    "choice of data structures; you are only allowed to preprocess the text from the documents in term\n",
    "of tokenization in which you can do case folding, stop-words removal and lemmatization. The stop\n",
    "word list is also provided to you with assignments files. Your query processing routine must \n",
    "address a query parsing, evaluation of the cost, and through executing it to fetch the required list\n",
    "of documents. The list of documents should be filtered with an alpha value say (alpha = 0.05), A\n",
    "command line interface is simply required to demonstrate the working model. You are also\n",
    "provided by a set of 10 queries, for evaluating your implementation.\n",
    "Coding can be done in either Java, C/C++, Python, or C# programming language. There are\n",
    "additional marks for intuitive GUI for demonstrating the working VSM along with free text query\n",
    "search.\n",
    "\n",
    "Files Provided with this Assignment:\n",
    "\n",
    "1. Abstracts\n",
    "\n",
    "2. Stop-words list as a single file\n",
    "\n",
    "3. Queries Result-set (Gold Standard- 15 example queries)\n",
    "\n",
    "Evaluation/ Grading Criteria\n",
    "\n",
    "The grading will be done as per the scheme of implementations, query responses and matching\n",
    "with a gold standard (provided query set).\n",
    "\n",
    "Grading Criteria:\n",
    "\n",
    "Preprocessing (3 marks)\n",
    "\n",
    "Formation of Index (1 mark for code complexity 1 mark for saving and loading the indexes)\n",
    "\n",
    "Vector Space Model (2 marks)\n",
    "\n",
    "Query processing (2 marks)\n",
    "\n",
    "Code Clarity (1 mark)\n",
    "\n",
    "Bonus: GUI (1 mark for making the GUI 1 mark for Good Looking GUI)\n",
    "The proper clean and well commented code will get 05% more marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed399ef9-5918-44e3-8b2d-d1db0068e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries have been installed successfully\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "import math\n",
    "print(\"All libraries have been installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb65342-12c0-44d6-8c70-2939ecdb702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aarib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aarib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aarib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024d5f38-c065-43d1-a0a7-4350f3ec36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.txt', '10.txt', '100.txt', '101.txt', '102.txt']\n"
     ]
    }
   ],
   "source": [
    "#Setting dataset path and checking the abstracts.rar files\n",
    "dataset_path = r\"C:\\Users\\aarib\\6thSemester\\IR\\IRAssignment\\Assignment2\\Abstracts\"\n",
    "\n",
    "print(os.listdir(dataset_path)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69eb9c0d-f56b-4d27-a374-a39cf1878781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Statistical and Heuristic Models for Unsupervised Word Alignment\n",
      "\n",
      "statistical word alignmen\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.listdir(dataset_path)[0]  #Picking the first file\n",
    "sample_path = os.path.join(dataset_path, sample_file)\n",
    "\n",
    "with open(sample_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(content[:100])  #Only printing first 100 characters of first file to just check and avoid clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1291e892-32c4-46ea-8f9f-a4eebc8dfe1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 448\n",
      "First Sample document:\n",
      " Ensemble Statistical and Heuristic Models for Unsupervised Word Alignment\n",
      "\n",
      "statistical word alignment, ensemble learning, heuristic word alignment\n",
      "\n",
      "Statistical word alignment models need large amount of training data while they are weak in small-size corpora. This paper proposes a new approach of unsupervised hybrid word alignment technique using ensemble learning method. This algorithm uses three base alignment models in several rounds to generate alignments. The ensemble algorithm uses a weighed scheme for resampling training data and a voting score to consider aggregated alignments. The underlying alignment algorithms used in this study include IBM Model 1, 2 and a heuristic method based on Dice measurement. Our experimental results show that by this approach, the alignment error rate could be improved by at least %15 for the base alignment models.\n"
     ]
    }
   ],
   "source": [
    "#List to store document contents which were provided in the abstracts.rar file.\n",
    "documents = []\n",
    "\n",
    "#Reading each .txt file in the folder\n",
    "for filename in os.listdir(dataset_path): #dataset_path defined above\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(dataset_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"windows-1252\") as file: \n",
    "            #encoding = \"utf-8\" did not work so tried \"latin-1\" which worked but \"windows-1252\" worked best according to the documents given. \n",
    "            documents.append(file.read())\n",
    "\n",
    "#Checking if loading was a success and the number of documents loaded\n",
    "print(f\"Total documents loaded: {len(documents)}\")\n",
    "print(\"First Sample document:\\n\", documents[0][:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8b6df-458c-475e-b66f-788707f10e23",
   "metadata": {},
   "source": [
    "## Preprocessing the Documents\n",
    "\n",
    "1. **Tokenization** (Splitting text into words)\n",
    "2. **Special Character Handling** (Replacing special characters such as /,_ with a space ' ' and storing hyphenated words both separately and in base form)\n",
    "3. **Case Folding** (Converting text into lowercase)  \n",
    "4. **Stop word removal** (Removing common words)  \n",
    "   Stop words list provided: *a, is, the, of, all, and, to, can, be, as, once, for, at, am, are, has, have, had, up, his, her, in, on, no, we, do*  \n",
    "5. **Lemmatization** (Reducing words to their base form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99d9e9e-a45c-48d0-a147-f873f549ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom stop words as provided by Stopword-list.txt\n",
    "my_stopwords = set([\n",
    "    \"a\", \"is\", \"the\", \"of\", \"all\", \"and\", \"to\", \"can\", \"be\", \"as\", \"once\", \n",
    "    \"for\", \"at\", \"am\", \"are\", \"has\", \"have\", \"had\", \"up\", \"his\", \"her\", \n",
    "    \"in\", \"on\", \"no\", \"we\", \"do\"\n",
    "])\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa8ae7d-0436-4fcc-aac9-2ce0d65a12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reusable function for preprocessing a single text string (for docs or queries)\n",
    "def preprocess_text(text, for_query=False):\n",
    "    #Only duplicate text if not for query\n",
    "    #if not for_query:\n",
    "        #text = text.replace(\"-\", \" \") + \" \" + text\n",
    "    #else:\n",
    "    #text = text.replace(\"-\", \" \") #Removed this for the time being to check k-means \n",
    "\n",
    "    #Replace \"/\", \"_\" with spaces\n",
    "    #text = re.sub(r'[/_]', ' ', text)\n",
    "\n",
    "    #Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    #Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    #Stopword removal\n",
    "    filtered_tokens = [word for word in tokens if word not in my_stopwords]\n",
    "\n",
    "    # Simple lemmatization - treats all words as nouns by default\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "\n",
    "#Function to preprocess all .txt files in the given folder\n",
    "def preprocess_documents(dataset_path):\n",
    "    processed_docs = {}  #Dictionary to store preprocessed tokens per document\n",
    "\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(dataset_path, filename)\n",
    "            with open(file_path, \"r\", encoding=\"windows-1252\") as file:\n",
    "                text = file.read()\n",
    "\n",
    "            #Preprocess the content using function\n",
    "            tokens = preprocess_text(text)\n",
    "            processed_docs[filename] = tokens\n",
    "\n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c556f59-fbfa-43ce-9a6b-6e535a3b49c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'processing', 'technique']\n"
     ]
    }
   ],
   "source": [
    "processed_docs = preprocess_documents(dataset_path)\n",
    "\n",
    "query = \"images processing techniques\"\n",
    "processed_query = preprocess_text(query, for_query = True)\n",
    "print(processed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be80a5c-6f9c-421e-96a4-059b31c1b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human']\n"
     ]
    }
   ],
   "source": [
    "processed_docs = preprocess_documents(dataset_path)\n",
    "\n",
    "query = \"humans\"\n",
    "processed_query = preprocess_text(query, for_query = True)\n",
    "print(processed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5be3818-86e5-4a4c-b2d5-0c636eb93edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supervised', 'kernel', 'k-means', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "processed_docs = preprocess_documents(dataset_path)\n",
    "\n",
    "query = \"supervised kernel k-means cluster\"\n",
    "processed_query = preprocess_text(query, for_query = True)\n",
    "print(processed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16903260-f01a-45a7-a991-3ae23185114f",
   "metadata": {},
   "source": [
    "### VSM\n",
    "### Vocabulary, TF and DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2393102-03d0-4dfe-b9f7-bc782496d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an empty set to store the unique vocabulary(terms) across all documents\n",
    "vocab = set()\n",
    "\n",
    "#Dictionary to store term frequency(TF) for each document\n",
    "tf_dict = {}\n",
    "\n",
    "#Counter to store document frequency(DF) for each term(in how many documents a term appears)\n",
    "df_counter = Counter()\n",
    "\n",
    "#Looping through each document and its preprocessed list of tokens\n",
    "for doc, tokens in processed_docs.items():\n",
    "    \n",
    "    #Counting the frequency of each term in the current document\n",
    "    tf = Counter(tokens)\n",
    "    \n",
    "    #saving the term frequency dictionary for the current document using its filename as the key \n",
    "    tf_dict[doc] = tf\n",
    "\n",
    "    #For each term in the document, increment the DF count (once per document)\n",
    "    for term in tf:\n",
    "        df_counter[term] += 1\n",
    "    \n",
    "    #Add the tokens from this document to the global vocabulary set as it is a set, onky unique terms will be added\n",
    "    vocab.update(tokens)\n",
    "\n",
    "#Sort the vocabulary to create a consistent order for vector representation\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "#Calculate the total number of documents(used later for IDF calculation)\n",
    "N = len(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af47e10-8892-4373-a6dc-80857c9f54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store TF-IDF vectors for each document\n",
    "doc_vectors = {}\n",
    "\n",
    "#Function to compute the TF-IDF vector for a single document\n",
    "def compute_tfidf_vector(tf, df_counter, N):\n",
    "    vector = []  #This will hold the tf-idf values for all terms in the vocabulary(in order)\n",
    "\n",
    "    #Iterating over the global vocabulary to ensure consistent term ordering\n",
    "    for term in vocab:\n",
    "        #Getting the term frequency of 'term' in the current document\n",
    "        tf_val = tf.get(term, 0)  #If the term is not in the document, return 0\n",
    "\n",
    "        #Getting the document frequency of the term (in how many documents it appears)\n",
    "        df_val = df_counter.get(term, 1)  #To avoid division by zero, default to 1 if term appears in no documents\n",
    "\n",
    "        #Computing tf-idf: tf * log(N / df)\n",
    "        tfidf = tf_val * math.log(N / df_val)\n",
    "\n",
    "        #Appending the tf-idf value for this term to the document vector\n",
    "        vector.append(tfidf)\n",
    "\n",
    "    return vector  #Return the full tf-idf vector for the document\n",
    "\n",
    "#Compute the TF-IDF vector for each document in the corpus\n",
    "for doc in processed_docs:\n",
    "    #tf_dict[doc] contains the term frequencies for the current document\n",
    "    doc_vectors[doc] = compute_tfidf_vector(tf_dict[doc], df_counter, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e376c2-4d5b-4011-bc38-661fdddafe93",
   "metadata": {},
   "source": [
    "#### Building the Indexes, Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40abce2c-dff8-4584-9b24-896168ba3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#Inverted Index     (term -> set of document IDs)\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for doc_id, tokens in processed_docs.items():\n",
    "    for token in set(tokens):  #using set to avoid duplicate doc_ids\n",
    "        inverted_index[token].add(doc_id)\n",
    "\n",
    "#converting sets to sorted lists for consistent output\n",
    "for term in inverted_index:\n",
    "    inverted_index[term] = sorted(list(inverted_index[term]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4224869a-54a0-4280-8d62-4f580cb08a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Index   (term -> dict of doc_id -> list of positions)\n",
    "positional_index = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for doc_id, tokens in processed_docs.items():\n",
    "    for pos, token in enumerate(tokens):\n",
    "        positional_index[token][doc_id].append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ffb2ea-7ba9-4952-b6c0-de635ae4d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Saving\n",
    "with open(\"inverted_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict(inverted_index), f)\n",
    "\n",
    "with open(\"positional_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict(positional_index), f)\n",
    "\n",
    "#Loading\n",
    "with open(\"inverted_index.pkl\", \"rb\") as f:\n",
    "    inverted_index = pickle.load(f)\n",
    "\n",
    "with open(\"positional_index.pkl\", \"rb\") as f:\n",
    "    positional_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab31dc3-f53d-4fdc-9279-613902ad3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    #Compute the dot product of the two vectors\n",
    "    #Dot product = sum of element-wise multiplication\n",
    "    #The zip() function takes two or more iterables and pairs up elements at the same index from each iterable.\n",
    "    dot = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    \n",
    "    #Compute the L2 norm (magnitude) of vec1\n",
    "    norm1 = math.sqrt(sum(a * a for a in vec1))\n",
    "    \n",
    "    #Compute the L2 norm (magnitude) of vec2\n",
    "    norm2 = math.sqrt(sum(b * b for b in vec2))\n",
    "    \n",
    "    #Return the cosine similarity: dot product divided by product of norms\n",
    "    #The tiny constant (1e-10) prevents division by zero when both vectors are zero\n",
    "    return dot / (norm1 * norm2 + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f19b05-1605-4e02-afd9-f5285b5a926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process a user query using the Vector Space Model (VSM)\n",
    "def process_query(query, alpha=0.001, top_k=40):\n",
    "    #Step 1: Preprocess the query using the same preprocessing as the documents\n",
    "    query_tokens = preprocess_text(query, for_query=True)\n",
    "    \n",
    "    #Step 2: Compute term frequency for the query\n",
    "    tf_q = Counter(query_tokens)\n",
    "    \n",
    "    #Step 3: Convert query term frequencies to a TF-IDF vector using the same vocabulary and df values\n",
    "    query_vec = compute_tfidf_vector(tf_q, df_counter, N)\n",
    "    \n",
    "    #Step 4: Initialize list to hold similarity scores\n",
    "    similarities = []\n",
    "    \n",
    "    #Step 5: Compute cosine similarity between query vector and each document vector\n",
    "    for doc, vec in doc_vectors.items():\n",
    "        sim = cosine_similarity(query_vec, vec)\n",
    "        \n",
    "        #Step 6: Only include documents whose similarity score is above the threshold alpha\n",
    "        if sim >= alpha:\n",
    "            doc_num = int(doc.replace(\".txt\", \"\")) # Extract numeric doc ID\n",
    "            similarities.append((doc_num, sim))\n",
    "    \n",
    "    #Step 7: Sort the documents by similarity score in descending order and return the top k\n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b0501-5942-45aa-b1a3-34042a5ac96e",
   "metadata": {},
   "source": [
    "### Checking Golden Queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfb82ae-d63a-426a-9a0a-ec6bdfdec5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21: 0.0654\n",
      "24: 0.1113\n",
      "174: 0.1945\n",
      "175: 0.0527\n",
      "176: 0.1109\n",
      "177: 0.1439\n",
      "213: 0.0690\n",
      "245: 0.0658\n",
      "246: 0.0842\n",
      "247: 0.1251\n",
      "250: 0.1188\n",
      "254: 0.0839\n",
      "258: 0.0501\n",
      "267: 0.2177\n",
      "273: 0.0969\n",
      "278: 0.1885\n",
      "279: 0.2852\n",
      "280: 0.1381\n",
      "281: 0.1197\n",
      "325: 0.1075\n",
      "345: 0.1312\n",
      "346: 0.1482\n",
      "347: 0.1328\n",
      "348: 0.1486\n",
      "352: 0.1264\n",
      "358: 0.0507\n",
      "360: 0.0802\n",
      "362: 0.0697\n",
      "374: 0.0846\n",
      "376: 0.0908\n",
      "380: 0.0814\n",
      "396: 0.2540\n",
      "397: 0.2404\n",
      "398: 0.0885\n",
      "401: 0.0983\n",
      "405: 0.0649\n",
      "415: 0.1574\n",
      "421: 0.0817\n",
      "432: 0.1072\n"
     ]
    }
   ],
   "source": [
    "#1. deep\n",
    "query = \"deep\"  #Query string\n",
    "results = process_query(query, top_k = 39) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  # Display document name and its cosine similarity with the query\n",
    "\n",
    "#258 coming extra in result rest all matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2568ef6c-78de-4470-be14-8c67006bd4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.1925\n",
      "35: 0.0503\n",
      "93: 0.0321\n",
      "101: 0.0730\n",
      "172: 0.0711\n",
      "174: 0.0488\n",
      "213: 0.0433\n",
      "257: 0.0394\n",
      "413: 0.0394\n",
      "435: 0.0488\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "query = \"weak heuristic\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 12) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c70e3ea-3c43-452e-8dcc-f8153b268d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between query and Document 391: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#CHECKING WHY 391 GOT MISSED IN RESULTS\n",
    "#Preprocess the query text\n",
    "query = \"weak heuristic\"\n",
    "\n",
    "#Step 1: Preprocess the query (like how documents are preprocessed)\n",
    "query_tokens = preprocess_text(query, for_query=True)\n",
    "\n",
    "#Step 2: Compute the term frequency for the query\n",
    "tf_q = Counter(query_tokens)\n",
    "\n",
    "#Step 3: Convert the query's term frequencies to a TF-IDF vector\n",
    "query_vec = compute_tfidf_vector(tf_q, df_counter, N)\n",
    "\n",
    "#Step 4: Retrieve the TF-IDF vector for Document 391\n",
    "doc_391_vec = doc_vectors.get(\"391.txt\")\n",
    "\n",
    "#Step 5: Compute cosine similarity between the query vector and document 391's vector\n",
    "cosine_sim = cosine_similarity(query_vec, doc_391_vec)\n",
    "\n",
    "#Step 6: Print the similarity score\n",
    "print(f\"Cosine Similarity between query and Document 391: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b977eda6-e60b-4d42-b0cf-d19b572dc2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: 0.0690\n",
      "45: 0.0909\n",
      "53: 0.1440\n",
      "66: 0.0739\n",
      "101: 0.0638\n",
      "277: 0.0557\n",
      "310: 0.1262\n",
      "311: 0.1081\n",
      "364: 0.1975\n",
      "426: 0.1162\n",
      "445: 0.0799\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "query = \"principle component analysis\"  #Query string\n",
    "results = process_query(query, alpha = 0.05) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3255f24e-d605-4f0e-ab06-857b4989e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: 0.0403\n",
      "10: 0.0773\n",
      "21: 0.0576\n",
      "22: 0.0373\n",
      "23: 0.0899\n",
      "26: 0.1659\n",
      "30: 0.1460\n",
      "63: 0.0146\n",
      "83: 0.0280\n",
      "98: 0.0202\n",
      "101: 0.0266\n",
      "127: 0.0745\n",
      "145: 0.0655\n",
      "162: 0.0227\n",
      "164: 0.0245\n",
      "171: 0.0375\n",
      "174: 0.0229\n",
      "186: 0.0950\n",
      "187: 0.0267\n",
      "191: 0.1149\n",
      "194: 0.0392\n",
      "203: 0.0197\n",
      "230: 0.0189\n",
      "247: 0.0184\n",
      "249: 0.0566\n",
      "250: 0.5117\n",
      "255: 0.0249\n",
      "256: 0.0208\n",
      "265: 0.0214\n",
      "273: 0.0285\n",
      "289: 0.0198\n",
      "345: 0.0578\n",
      "359: 0.0142\n",
      "369: 0.0314\n",
      "383: 0.1497\n",
      "391: 0.0212\n",
      "395: 0.0543\n",
      "403: 0.0243\n",
      "426: 0.0915\n",
      "428: 0.1046\n",
      "436: 0.0244\n",
      "444: 0.0612\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "query = \"human interaction\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 100) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "476a995f-4a44-432a-bb52-cb9ee361b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between query and Document 203: 0.0197\n"
     ]
    }
   ],
   "source": [
    "#CHECKING WHY 203 GOT MISSED IN RESULTS, It got missed due to a lower value of top_k\n",
    "#Preprocess the query text\n",
    "query = \"human interaction\"\n",
    "\n",
    "#Step 1: Preprocess the query (like how documents are preprocessed)\n",
    "query_tokens = preprocess_text(query, for_query=True)\n",
    "\n",
    "#Step 2: Compute the term frequency for the query\n",
    "tf_q = Counter(query_tokens)\n",
    "\n",
    "#Step 3: Convert the query's term frequencies to a TF-IDF vector\n",
    "query_vec = compute_tfidf_vector(tf_q, df_counter, N)\n",
    "\n",
    "#Step 4: Retrieve the TF-IDF vector for Document 391\n",
    "doc_203_vec = doc_vectors.get(\"203.txt\")\n",
    "\n",
    "#Step 5: Compute cosine similarity between the query vector and document 391's vector\n",
    "cosine_sim = cosine_similarity(query_vec, doc_203_vec)\n",
    "\n",
    "#Step 6: Print the similarity score\n",
    "print(f\"Cosine Similarity between query and Document 203: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aec2e8f1-f69e-4c47-8672-57a28854da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31: 0.1413\n",
      "79: 0.1922\n",
      "106: 0.1019\n",
      "122: 0.2590\n",
      "123: 0.0859\n",
      "125: 0.0931\n",
      "158: 0.1222\n",
      "173: 0.1326\n",
      "198: 0.1085\n",
      "235: 0.1641\n",
      "242: 0.1819\n",
      "243: 0.1060\n",
      "244: 0.0894\n",
      "258: 0.0938\n",
      "275: 0.1790\n",
      "277: 0.0873\n",
      "280: 0.1222\n",
      "304: 0.1483\n",
      "321: 0.1606\n",
      "326: 0.0953\n",
      "342: 0.2135\n",
      "349: 0.3669\n",
      "351: 0.1770\n",
      "383: 0.1522\n",
      "401: 0.0920\n",
      "446: 0.1280\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "query = \"supervised kernel k-means cluster\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 26) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ed4e9bf-df64-4c5d-bbe2-41b904e31575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Docs: {291, 167, 264, 427, 430, 334, 368, 177, 241, 53, 245, 281, 124, 447}\n",
      "Extra Docs: {321, 258, 198, 326, 106, 235, 79, 304, 401, 277, 342, 349, 446, 351}\n",
      "Correct Matches: {383, 173, 242, 275, 243, 244, 280, 122, 123, 125, 158, 31}\n"
     ]
    }
   ],
   "source": [
    "#Checking my mismatch.......................:(\n",
    "gold_docs = set([31, 53, 122, 123, 124, 125, 158, 167, 173, 177, 241, 242, 243, 244, \n",
    "                 245, 264, 275, 280, 281, 291, 334, 368, 383, 427, 430, 447])\n",
    "\n",
    "your_docs = set([doc for doc, _ in results])\n",
    "\n",
    "print(\"Missing Docs:\", gold_docs - your_docs)\n",
    "print(\"Extra Docs:\", your_docs - gold_docs)\n",
    "print(\"Correct Matches:\", gold_docs & your_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3d9f1a9-7c03-4857-911a-0191c314c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37: 0.1598\n",
      "40: 0.0171\n",
      "62: 0.0236\n",
      "72: 0.0868\n",
      "80: 0.0425\n",
      "168: 0.0489\n",
      "225: 0.0174\n",
      "259: 0.0746\n",
      "263: 0.0210\n",
      "328: 0.0668\n",
      "332: 0.1316\n",
      "333: 0.0179\n",
      "355: 0.0570\n",
      "368: 0.0270\n",
      "391: 0.0212\n",
      "400: 0.0630\n",
      "433: 0.1095\n",
      "447: 0.0408\n",
      "448: 0.4611\n"
     ]
    }
   ],
   "source": [
    "#6.\n",
    "query = \"patients depression anxiety\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 26) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acba8310-9efc-4f66-af12-8eccbbd88333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Docs: set()\n",
      "Extra Docs: set()\n",
      "Correct Matches: {259, 263, 391, 400, 37, 168, 40, 433, 62, 447, 448, 72, 328, 332, 333, 80, 225, 355, 368}\n"
     ]
    }
   ],
   "source": [
    "#Checking my mismatch.......................:(     NOO MISMATCH!!\n",
    "gold_docs = set([37 , 40 , 62 , 72 , 80 , 168 , 225 , 259 , 263 , 328 , 332 , 333 , 355 , 368 , 391 , \n",
    "400 , 433 , 447 , 448])\n",
    "\n",
    "your_docs = set([doc for doc, _ in results])\n",
    "\n",
    "print(\"Missing Docs:\", gold_docs - your_docs)\n",
    "print(\"Extra Docs:\", your_docs - gold_docs)\n",
    "print(\"Correct Matches:\", gold_docs & your_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eee0004-3908-4433-a195-1e8447d51284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 0.0662\n",
      "21: 0.0496\n",
      "30: 0.0377\n",
      "31: 0.0708\n",
      "74: 0.0662\n",
      "79: 0.1088\n",
      "106: 0.0938\n",
      "113: 0.1215\n",
      "125: 0.1703\n",
      "126: 0.0626\n",
      "134: 0.2418\n",
      "168: 0.0384\n",
      "179: 0.0527\n",
      "184: 0.0357\n",
      "196: 0.0790\n",
      "198: 0.1240\n",
      "200: 0.0412\n",
      "215: 0.0692\n",
      "235: 0.0569\n",
      "266: 0.2336\n",
      "271: 0.1693\n",
      "274: 0.0767\n",
      "275: 0.0621\n",
      "293: 0.0631\n",
      "326: 0.1089\n",
      "331: 0.0612\n",
      "342: 0.3553\n",
      "350: 0.0869\n",
      "351: 0.2023\n",
      "377: 0.0557\n",
      "379: 0.0634\n",
      "394: 0.0412\n",
      "407: 0.1065\n",
      "446: 0.1464\n",
      "448: 0.0647\n"
     ]
    }
   ],
   "source": [
    "#7.\n",
    "query = \"local global clusters\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 35) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82b20f67-ad47-4f92-a021-9f2b4bdfdbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Docs: {257, 38, 295, 136, 423, 361, 76, 335, 336, 242, 19, 211, 54, 23, 26, 156, 158}\n",
      "Extra Docs: {448, 350, 3, 293, 198, 326, 200, 351, 74, 106, 235, 79, 274, 275, 184, 379, 446, 31}\n",
      "Correct Matches: {126, 196, 134, 168, 266, 394, 331, 271, 113, 179, 21, 342, 407, 377, 215, 125, 30}\n"
     ]
    }
   ],
   "source": [
    "#Checking my mismatch.......................:(\n",
    "gold_docs = set([19 , 21 , 23 , 26 , 30 , 38 , 54 , 76 , 113 , 125 , 126 , 134 , 136 , 156 , 158 , 168 , \n",
    "179 , 196 , 211 , 215 , 242 , 257 , 266 , 271 , 295 , 331 , 335 , 336 , 342 , 361 , 377 , \n",
    "394 , 407 , 423])\n",
    "\n",
    "your_docs = set([doc for doc, _ in results])\n",
    "\n",
    "print(\"Missing Docs:\", gold_docs - your_docs)\n",
    "print(\"Extra Docs:\", your_docs - gold_docs)\n",
    "print(\"Correct Matches:\", gold_docs & your_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df6c94c4-3cc7-412e-9406-3c77161e8ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38: 0.0816\n",
      "92: 0.0231\n",
      "136: 0.0221\n",
      "257: 0.0199\n",
      "420: 0.0324\n",
      "428: 0.0180\n",
      "446: 0.0189\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "query = \"synergy analysis\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 7) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3f23028-b717-40a2-890e-19da40c7afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178: 0.1355\n",
      "362: 0.3238\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "query = \"github mashup apis\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 2) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2b9c42e-0e87-457b-8a34-010a15b1461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: 0.3008\n",
      "35: 0.0497\n",
      "39: 0.2033\n",
      "62: 0.0666\n",
      "65: 0.0791\n",
      "93: 0.0424\n",
      "117: 0.1422\n",
      "118: 0.2130\n",
      "119: 0.4109\n",
      "155: 0.0319\n",
      "196: 0.0517\n",
      "243: 0.0883\n",
      "244: 0.0744\n",
      "255: 0.0703\n",
      "271: 0.0707\n",
      "290: 0.0485\n",
      "324: 0.0249\n",
      "332: 0.0680\n",
      "370: 0.0227\n",
      "440: 0.1192\n",
      "442: 0.0659\n",
      "448: 0.1418\n"
     ]
    }
   ],
   "source": [
    "#10.\n",
    "query = \"Bayesian nonparametric\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 23) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba42a0a5-19ae-4520-9f33-e82e186e6ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72: 0.1071\n",
      "148: 0.1429\n",
      "391: 0.0522\n"
     ]
    }
   ],
   "source": [
    "#11.\n",
    "query = \"diabetes and obesity\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 3) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4d0d097-81dd-45c7-ae9a-33ffd0c6ab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181: 0.3273\n",
      "193: 0.3763\n",
      "379: 0.0655\n"
     ]
    }
   ],
   "source": [
    "#12.\n",
    "query = \"bootstrap\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 3) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "168670e8-0c54-4a2f-a5cc-53b3ae7e8fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.1969\n",
      "2: 0.2002\n",
      "3: 0.3087\n",
      "32: 0.0970\n",
      "52: 0.0323\n",
      "89: 0.3205\n",
      "105: 0.1038\n",
      "120: 0.1455\n",
      "171: 0.0876\n",
      "198: 0.2313\n",
      "229: 0.1751\n",
      "256: 0.2913\n",
      "262: 0.0299\n",
      "268: 0.0468\n",
      "284: 0.3337\n",
      "310: 0.0493\n",
      "311: 0.1553\n",
      "327: 0.1343\n",
      "352: 0.1737\n",
      "378: 0.1739\n",
      "386: 0.0581\n",
      "425: 0.0529\n"
     ]
    }
   ],
   "source": [
    "#13.\n",
    "query = \"ensemble\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 23) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73f36247-3aaf-4568-beeb-1e5130e325e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11: 0.0801\n",
      "16: 0.2345\n",
      "22: 0.0338\n",
      "69: 0.1673\n",
      "110: 0.0526\n",
      "129: 0.0512\n",
      "149: 0.2765\n",
      "197: 0.0952\n",
      "230: 0.0456\n",
      "251: 0.0555\n",
      "257: 0.1336\n",
      "260: 0.0998\n",
      "289: 0.0954\n",
      "305: 0.0569\n",
      "312: 0.0677\n",
      "323: 0.0782\n",
      "335: 0.1596\n",
      "381: 0.0377\n",
      "439: 0.0463\n",
      "445: 0.0479\n"
     ]
    }
   ],
   "source": [
    "#14.\n",
    "query = \"markov\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 23) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c96810-3934-4cca-8196-94b7ed1bed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44: 0.0149\n",
      "101: 0.0194\n",
      "112: 0.0128\n",
      "118: 0.0122\n",
      "138: 0.0129\n",
      "140: 0.0170\n",
      "166: 0.0338\n",
      "195: 0.0570\n",
      "208: 0.0160\n",
      "218: 0.0164\n",
      "227: 0.0155\n",
      "230: 0.1764\n",
      "239: 0.0157\n",
      "250: 0.0169\n",
      "257: 0.0134\n",
      "281: 0.0128\n",
      "283: 0.0138\n",
      "298: 0.0221\n",
      "318: 0.0147\n",
      "354: 0.0193\n",
      "422: 0.0184\n",
      "426: 0.0125\n",
      "436: 0.0177\n"
     ]
    }
   ],
   "source": [
    "#15.\n",
    "query = \"prioritize and critical correlate\"  #Query string\n",
    "results = process_query(query, alpha = 0.001, top_k = 23) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba14a725-cee1-43c1-8aae-074f0e2c0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357: 0.2795\n",
      "398: 0.2137\n"
     ]
    }
   ],
   "source": [
    "#CAN RUN YOUR OWN CHANGED QUERY HERE\n",
    "query = \"robust against noise\"  #Query string\n",
    "results = process_query(query, alpha = 0.2, top_k = 20) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd3a89b1-654b-4f1e-942a-d3b23cdf9cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238: 0.5247\n"
     ]
    }
   ],
   "source": [
    "#CAN RUN YOUR OWN CHANGED QUERY HERE\n",
    "query = \"grammar induction\"  #Query string\n",
    "results = process_query(query, alpha = 0.5, top_k = 20) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f14f1ff-39d7-459b-8d80-4f3257e9b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18: 0.2565\n",
      "444: 0.3563\n"
     ]
    }
   ],
   "source": [
    "#15. CAN RUN YOUR OWN CHANGED QUERY HERE\n",
    "query = \"lifelong chess patterns\"  #Query string\n",
    "results = process_query(query, alpha = 0.1, top_k = 20) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb114b-8545-4e28-b8a0-14827a2515c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN RUN YOUR OWN CHANGED QUERY HERE\n",
    "query = \"\"  #Query string\n",
    "results = process_query(query, alpha = 0.1, top_k = 20) #Getting ranked results using VSM\n",
    "results_sorted = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "#Printing the top results with similarity scores sorted by document number in ascending order\n",
    "for doc, score in results_sorted:\n",
    "    print(f\"{doc}: {score:.4f}\")  #Displaying document name and its cosine similarity with the query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
